# Going Further with the Unix Shell {#r-rse-bash-advanced}

```{r r-rse-bash-advanced-setup, include=FALSE}
source("_common.R")
```

Chapter \@ref(r-rse-bash-basics) explained how we can use the command line
to do all of the things we can do with a graphical file explorer,
and how to go beyond that to combine commands in powerful ways using pipes and redirection.
This chapter extends those ideas to show how we can save commands in files
to create new tools of our own,
and how to use a more powerful version of [wildcards][wildcard]
to extract data from files.

## How can I create new commands of my own? {#r-rse-bash-advanced-script}

Loops and history let us do tasks repeatedly,
but we can go even further and save commands in files
so that we can re-run complex sequences of operations with a few keystrokes.
For historical reasons,
a file full of shell commands is usually called a [shell script][shell-script],
but it is really just another kind of program.

Let's start by going into `climate-data` and creating a new file called `years.sh`
to hold our shell script:

```shell
$ cd ~/climate-data
$ nano years.sh
```

Insert this line:

```text
cut -d , -f 2 cleaned/bellambi_temp.csv
```

This uses the `cut` command to split the CSV file on commas
and select the second field from each line.
(The option `-d` stands for [delimiter][delimiter]:
we can provide any character we want to split lines on colons, spaces, and so on.)
Note that we do *not* put a dollar sign `$` at the front of the line:
we have been showing that for interactive commands,
but in this case we are putting the command in a file rather than running it immediately.

Once we have added this line to the file,
we can write it out with <kbd>Ctrl</kbd>+<kbd>O</kbd>
and exit with <kbd>Ctrl</kbd>+<kbd>O</kbd>.
`ls` shows that our file now exists:

```shell
$ ls
```

```text
NOTES           backup/         cleaned/        raw/            thesis.pdf      years.sh
README.md       bin/            docs/           thesis.md       tofu.config
```

and we can check its contents using `cat years.sh`.
More importantly,
we can now ask the shell to run this file:

```shell
$ bash years.sh
```

```text
Year
1997
1997
...many more lines...
2019
2019
2019
```

Sure enough,
our script's output is exactly what we would get if we ran the command directly.
For example,
we can count how many lines of output there are by putting our script in a pipeline:

```shell
$ bash years.sh | wc -l
```

```text
    8314
```

What if we want to remove duplicates from the output?
The command `uniq` will do what we want,
so let's edit our script,
add it,
look at our changes,
and then run the modified script:

```shell
$ nano years.sh
$ cat years.sh
```

```text
cut -d , -f 2 cleaned/bellambi_temp.csv | uniq
```

```shell
$ bash years.sh
```

```text
Year
1997
1998
1999
...one line per year...
2017
2018
2019
```

Once again,
we can pipe the output of our script into other commands
just as we would pipe the output from any other program:

```shell
$ bash years.sh | wc -l
```

```text
      24
```

## How can I make my scripts more versatile? {#r-rse-bash-advanced-params}

Creating a list of distinct years in a single specific data file isn't all that useful.
What we really want is a way to get the years from any of our files.
Let's edit `years.sh` again and replace `cleaned/bellambi_temp.csv`
with a special variable `$1`.
Once our change is made,
`years.sh` should contain:

```text
cut -d , -f 2 $1 | uniq
```

Inside a shell script,
`$1` means "the first argument on the command line".
We can now run our script like this:

```shell
$ bash years.sh cleaned/bellambi_temp.csv
```

and get exactly the same output as before,
or give it a different filename:

```shell
$ bash years.sh cleaned/andamooka_prec.csv
```

and get the years from that file instead.

Our little script is now doing something useful,
but it may take the next person who reads it a moment to figure out exactly what that is.
We can improve our script by adding [comments][comment] at the top:

```text
# Select distinct years from column 2 of climate data file.
# Usage: bash years.sh /path/to/file.csv
cut -d , -f 2 $1 | uniq
```

As in R,
a comment starts with a `#` character and runs to the end of the line.
The computer ignores comments,
but they help people (including our future self) understand and use scripts.

Let's make one more change to our script.
Instead of always selecting the second column,
let's have it select whatever column the user specified:

```text
# Select distinct years from column 2 of climate data file.
# Usage: bash years.sh /path/to/file.csv
cut -d , -f $2 $1 | uniq
```

The change is very small:
we have replaced the fixed column number `2` with a reference to the special variable `$2`,
which is assigned the value of the second command-line argument we give the script when we run it.
Let's check that it works by asking for column 1,
which is the weather station ID:

```shell
$ bash years.sh cleaned/bellambi_prec.csv 1
```

```text
Station
68228
```

But we have made a common mistake:
we have changed the script without changing the comment.
A description that sends readers in the wrong direction is worse than none at all,
so we should go back and update it.
We should probably also change the script's name from `years.sh` to `column.sh`,
since a program's name is the first piece of documentation anyone sees.

And finally,
we should add one more command to our pipeline.
If we run the script as-is for column 3,
which holds months,
we get this:

```shell
$ bash years.sh cleaned/bellambi_prec.csv 3
```
Month
1
2
...
11
12
1
2
...
8
9
10
```

Duplicate months aren't removed because `uniq` only removes *adjacent* duplicates.
If we want to get rid of them all,
we must sort the data so that redundant lines are next to one another.
Here's our final script:

```text
# Select distinct values from a column of a climate data file.
# Usage: bash years.sh /path/to/file.csv column_number
cut -d , -f $2 $1 | uniq
```

## How can I turn interactive work into a script? {#r-rse-bash-advanced-capture}

Suppose we have just run a series of commands that did something useful,
such as creating a plot for a paper.
Instead of typing those commands into a file in an editor
(and potentially getting them wrong)
we can run this:

```shell
$ history 6 > make-figure-3.sh
```

to put the most recent five commands in `make-figure-3.sh`.

```text
297 bash stats.sh cleaned/*_temp.csv > temperature_stats.csv
298 bash trim-outliers.sh temperature_stats.csv > plot_data.txt
299 date
300 ygraph --format scatter --color bw --borders none plot_data.txt figure-3.png
301 rm temperature_stats.csv plot_data.txt
302 history 6 > make-figure-3.sh
```

It only takes a few moments in an editor to remove the serial numbers
and delete the use of `date`
(which prints the current time and date)
to create a script that accurately captures what we actually did.
This is how we usually develop shell scripts:
run commands interactively a few times to make sure they are doing the right thing,
then save our recent history to a file and turn that into a reusable script.

## How can I find things in a file? {#r-rse-bash-advanced-grep}

We can use `head` and `tail` to select lines from a file by position,
but we also often want to select lines that contain certain values.
This operation is called [filtering][filter] When we are working with database tables or dataframes,
and in the shell,
we usually do it using a command called `grep`.
The name comes from "global regular expression print",
which was a common sequence of operations in early Unix text editors.
To show how `grep` works,
we will use a file that contains three haikus
taken from a 1998 competition in *Salon* magazine.

```shell
$ cat haiku.txt
```

```text
The Tao that is seen
Is not the true Tao, until
You bring fresh toner.

With searching comes loss
and the presence of absence:
"My Thesis" not found.

Yesterday it worked
Today it is not working
Software is like that.
```

> **Forever, or Five Years**
>
> We haven't linked to the original haikus because they don't appear to be on *Salon*'s site any longer.
> As [Jeff Rothenberg said][rothenberg-quote],
> "Digital information lasts forever—or five years, whichever comes first."
> Luckily, popular content often [has backups][rothenberg-backup].

Let's find lines that contain the word "not":

```shell
$ grep not haiku.txt
```

```text
Is not the true Tao, until
"My Thesis" not found
Today it is not working
```

Here, `not` is our (very simple) pattern.
`grep` searches the file line by line
and shows those lines that contain matches.
Let's search for the pattern `The`:

```shell
$ grep The haiku.txt
```

```text
The Tao that is seen
"My Thesis" not found.
```

Two lines match,
but in one of them,
our pattern is part of a larger word `Thesis`.
To restrict matching to lines containing `The` on its own,
we can give `grep` with the `-w` option:

```shell
$ grep -w The haiku.txt
```

```text
The Tao that is seen
```

What if we want to search for a phrase rather than a single word?

```shell
$ grep is not haiku.txt
```

```text
grep: not: No such file or directory
haiku.txt:The Tao that is seen
haiku.txt:"My Thesis" not found.
haiku.txt:Today it is not working
haiku.txt:Software is like that.
```

In this case,
`grep` uses `is` as the pattern
and tries to find it in the files `not` and `haiku.txt`.
It then tells us that the file `not` cannot be found,
but prints `haiku.txt` as a prefix to each other line of output
to tell us which file those lines came from.

If we want to give `grep` both words as a single argument,
we must wrap them in quotation marks:

```shell
$ grep "is not" haiku.txt
```

```text
Today it is not working
```

> **Quoting**
>
> Quotation marks aren't specific to `grep`:
> the shell interprets them before running the command,
> just as it expands wildcards to create actual filenames
> no matter what we're asking it to do.
> This allows us to do things like `head -n 5 "My Thesis.txt"`
> if we want to edit a file that has a space in its name.
> It is also why many programmers write `"$variable"` instead of just `$variable`
> when creating loops or shell scripts:
> if there's any chance at all that the variable's value will contain spaces,
> it's safest to quote it.

`grep` has many options—so many,
in fact,
that almost every letter of the alphabet means something to it:

```shell
$ man grep
```

```text
GREP(1)                   BSD General Commands Manual                  GREP(1)

NAME
     grep, egrep, fgrep, zgrep, zegrep, zfgrep -- file pattern searcher

SYNOPSIS
     grep [-abcdDEFGHhIiJLlmnOopqRSsUVvwxZ] [-A num] [-B num] [-C[num]]
          [-e pattern] [-f file] [--binary-files=value] [--color[=when]]
          [--colour[=when]] [--context[=num]] [--label] [--line-buffered]
          [--null] [pattern] [file ...]
...more...
```

One of the most useful options is `-n`,
which numbers the lines that match:

```shell
$ grep -n it haiku.txt
```

```text
5:With searching comes loss
9:Yesterday it worked
10:Today it is not working
```

Another is `-i`,
which does case-insensitive matching:

We can combine options (i.e. flags) as we do with other Unix commands.
For example, let's find the lines that contain the word "the". We can combine
the option `-w` to find the lines that contain the word "the" and `-n` to number the lines that match:

```shell
$ grep -i to haiku.txt
```

```text
You bring fresh toner.
Today it is not working
```

We can combine options as with other commands:

```shell
$ grep -i -n haiku.txt
```

```text
3:You bring fresh toner.
10:Today it is not working
```

We can also invert the match—i.e., print lines that *don't* match the pattern—using `-v`:

```shell
$ grep -i -n -v to haiku.txt
```

```text
1:The Tao that is seen
2:Is not the true Tao, until
4:
5:With searching comes loss
6:and the presence of absence:
7:"My Thesis" not found.
8:
9:Yesterday it worked
11:Software is like that.
```

If we want to search several files at once,
all we have to do is give `grep` all of their names.
We will frequently use wildcards to do this,
so if we want to count how many records in our climate data come from the year 2001,
we can do this:

```shell
$ grep 2001 cleaned/*.csv | wc -l
```

```text
    2920
```

Finally,
the `-r` option (for "recursive") tells `grep` to search all of the files
in or below a directory:

```shell
$ grep -r . FIXME | wc -l
```

```text
      28
```

`grep`'s real power comes from the fact that its patterns can include
a powerful kind of wildcards called [regular expressions][regular-expression].
For example,
this command finds lines that start with the letter 'T':

```shell
$ grep -E "^T" haiku.txt
```

```text
The Tao that is seen
Today it is not working
```

The `-E` option tells `grep` to interpret the pattern as a regular expression
rather than taking it literally.
The quotes prevent the shell from treating any special characters in the pattern as wildcards,
and the `^` in front of the `T` means, "Only match at the start of the line."

Many tools support regular expressions:
we can use them in programming languages,
database queries,
online search engines,
and most text editors (though not Nano—its creators wanted to keep it as small as possible).
A wide range of tutorials are available online,
and @Goyv2012 is a useful companion if you need to go further.

## How can I find files? {#r-rse-bash-advanced-find}

While `grep` finds things in files,
the `find` command finds files themselves.
It also has a lot of options,
but unlike most Unix commands these are written as full words rather than abbreviations.
To show how it works,
we will explore the `docs` directory within `climate-data`:

```shell
$ cd docs
$ tree .
```

```text
.
├── bibliography.bib
├── chapter-1
│   └── index.html
├── chapter-2
│   └── index.html
├── chapter-3
│   └── index.html
├── figures
│   ├── figure-1.png
│   ├── figure-2.png
│   ├── figure-3.png
│   └── figure-4.png
└── index.html

4 directories, 9 files
```

This directory contains `index.html`, `bibliography.bib`, and four subdirectories:
three for chapters and one for figures.
For our first command,
let's run `find .` to find and list everything in this directory.
(As always,
`.` on its own means the current working directory,
which is where we want our search to start.)

```shell
$ find .
```

```text
.
./index.html
./chapter-1
./chapter-1/index.html
./figures
./figures/figure-4.png
./figures/figure-1.png
./figures/figure-3.png
./figures/figure-2.png
./chapter-3
./chapter-3/index.html
./chapter-2
./chapter-2/index.html
./bibliography.bib
```

If we only want to find directories,
we can tell `find` to show us things of type `d`:

```shell
$ find . -type d
```

```text
.
./chapter-1
./figures
./chapter-3
./chapter-2
```

If we change `-type d` to `-type f`
we get a listing of all the files instead:

```shell
$ find . -type f
```

```text
./index.html
./chapter-1/index.html
./figures/figure-4.png
./figures/figure-1.png
./figures/figure-3.png
./figures/figure-2.png
./chapter-3/index.html
./chapter-2/index.html
./bibliography.bib
```

Now let's try matching by name:

```shell
$ find . -name "*.png"
```

```text
./figures/figure-4.png
./figures/figure-1.png
./figures/figure-3.png
./figures/figure-2.png
```

As we said earlier,
the command line's power lies in combining tools.
We have seen how to do that with pipes;
let's use another technique to see how large our HTML files are:

```shell
$ wc -l $(find . -name "*.html")
```

```text
      16 ./index.html
      14 ./chapter-1/index.html
      15 ./chapter-3/index.html
      11 ./chapter-2/index.html
      56 total
```

When the shell executes this command,
it runs whatever is inside the `$()`
and then replaces `$()` with that command's output.
Since the output of `find` is the paths of four HTML files,
the shell constructs the command:

```shell
$ wc -l ./index.html ./chapter-1/index.html ./chapter-2/index.html ./chapter-3/index.html
```

which is what we wanted.
It is exactly like expanding the wildcard in `*.html`,
but more flexible.

We will often use `find` and `grep` together.
The first finds files whose names match a pattern,
while the second looks for lines inside those files that match another pattern.
For example,
we can look for the titles of all our HTML files:

```shell
$ grep "<title>" $(find . -name "*.html")
```

```text
./index.html:    <title>Climate Change in the Australian Subcontinent</title>
./chapter-1/index.html:    <title>Climate Change in the Australian Subcontinent: Introduction</title>
./chapter-3/index.html:    <title>Climate Change in the Australian Subcontinent: Methods</title>
./chapter-2/index.html:    <title>Climate Change in the Australian Subcontinent: Background</title>
```

We can also use `$()` expansion to create a list of filenames to use in a loop:

```shell
$ for page in $(find . -name "*.html")
> do
> cp $page $page.bak
> done
$ find . -name "*.bak"
```

```text
./chapter-1/index.html.bak
./index.html.bak
./chapter-3/index.html.bak
./chapter-2/index.html.bak
```

## How can I change the shell's settings? {#r-rse-bash-advanced-vars}

The shell is just a program, and like other programs, it has variables.
Those variables control its execution,
so by changing their values
we can change how the shell and other programs behave.

Let's run the command `set` and look at some of the variables in a typical shell session:

```shell
$ set
```

```text
COMPUTERNAME=TURING
HOME=/Users/amira
HOMEDRIVE=C:
HOSTNAME=TURING
HOSTTYPE=i686
NUMBER_OF_PROCESSORS=4
OS=Windows_NT
PATH=/Users/amira/bin:/usr/local/git/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin
PWD=/Users/amira
UID=1000
USERNAME=amira
...
```

There are quite a few—many more than are shown here.
And yes,
using `set` to *show* things might seem a little strange,
even for Unix,
but if we don't give it any arguments,
it might as well show us things we *could* set.

Every variable has a name.
By convention, variables that are always present are given upper-case names.
All shell variables' values are strings, even those (like `UID`) that look like numbers.
It's up to programs to convert these strings to other types when necessary.
For example, if a program wanted to find out how many processors the computer had,
it would convert the value of the `NUMBER_OF_PROCESSORS` variable from a string to an integer.

Similarly, some variables (like `PATH`) store lists of values.
In this case, the convention is to use a colon ':' as a separator.
If a program wants the individual elements of such a list,
it's the program's responsibility to split the variable's string value into pieces.

Let's have a closer look at `PATH`.
Its value defines the shell's [search path][search-path],
i.e., the list of directories that the shell looks in for runnable programs
when we type in a program name without specifying what directory it is in.

For example,
when we type a command like `analyze`,
the shell needs to decide whether to run `./analyze` (in our current directory)
or `/bin/analyze` (in a system directory).
The rule it uses is simple:
the shell checks each directory in the `PATH` variable in turn,
looking for a program with the requested name in that directory.
As soon as it finds a match, it stops searching and runs the program.

To show how this works,
here are the components of `PATH` listed one per line:

```shell
/Users/amira/bin
/usr/local/git/bin
/usr/bin
/bin
/usr/sbin
/sbin
/usr/local/bin
```

Suppose that our computer has three programs called `analyze`:
`/bin/analyze`,
`/usr/local/bin/analyze`,
and `/Users/amira/analyze`.
Since the shell searches the directories in the order they're listed in `PATH`,
it finds `/bin/analyze` first and runs that.
Since `/Users/amira` is not in our path,
Bash will *never* find the program `/Users/amira/analyze`
unless we type the path in explicitly
(for example,
as `./analyze` if we are in `/Users/amira`).

Let's show the value of the variable `HOME`:

```shell
$ echo HOME
```

```text
HOME
```

Whoops: this just prints "HOME", which isn't what we wanted
(though it is what we asked for).
Let's try this instead:

```shell
$ echo $HOME
```

```text
/Users/amira
```

The dollar sign tells the shell that we want the value of the variable named `HOME`;
as we have seen,
`echo` simply prints the literal string `HOME` if we omit it
(because that's what we want `echo` to do if we type `echo hello` or something similar).
This works just like wildcards:
the shell does the replacement before running the program we've asked for.
Thanks to this expansion, what we actually run is `echo /Users/amira`,
which displays the right thing.

Creating a variable is easy—we just assign a value to a name using "=",
and put quotes around the value if it contains spaces or special characters:

```shell
$ DEPARTMENT="Library Science"
$ echo $DEPARTMENT
```

```text
Library Science
```

To change the value, we just assign a new one:

```shell
$ DEPARTMENT="Information Science"
$ echo $DEPARTMENT
```

```text
Information Science
```

If we want to set some variables automatically every time we run a shell,
we can put commands to do this in a file called `.bashrc` in our home directory.
(The '.' character at the front prevents `ls` from listing this file
unless we specifically ask it to using `-a`.
The "rc" at the end is an abbreviation for "run commands",
which meant something really important decades ago,
and is now just a convention everyone follows without understanding why.)
For example,
here are two lines in `/Users/amira/.bashrc`:

```text
export DEPARTMENT="Library Science"
export TEMP_DIR=/tmp
export BACKUP_DIR=$TEMP_DIR/backup
```

These three lines create the variables `DEPARTMENT`,
`TEMP_DIR`,
and `BACKUP_DIR`,
and export them so that any programs the shell runs can see them as well.
Notice that `BACKUP_DIR`'s definition relies on the value of `TEMP_DIR`,
so that if we change where we put temporary files,
our backups will be relocated automatically.

While we're here,
it's also common to use the `alias` command to create shortcuts for things we frequently type.
For example, we can define the alias `backup`
to run `/bin/zback` with a specific set of arguments:

```shell
alias backup=/bin/zback -v --nostir -R 20000 $HOME $BACKUP_DIR
```

Aliases can save us a lot of typing, and hence a lot of typing mistakes.
The name of an alias can be the same as an existing command,
so we can use them to change the behavior of a familiar command:

```shell
# Long list format including hidden files
alias ls='ls -la'

# Print the file paths that were copied/moved
alias mv='mv -v'
alias cp='cp -v'

# Print the file paths that were removed
# and prompt if trying to remove move than three files
alias rm='rm -Iv'
```

We can find interesting suggestions for other aliases
by searching online for "sample bashrc".

## Summary {#r-rse-bash-advanced-summary}

FIXME: create concept map of advanced shell

The original Unix shell was created in 1971,
and will soon celebrate its fiftieth anniversary.
Its syntax may be cryptic and inconsistent,
but few programs have lasted as long,
and fewer still remain in daily use.
The secret to its success was and is its generality:
any program that reads text from standard input
and prints text to standard output
can work with any other.

FIXME: write a better summary for advanced shell

## Exercises {#r-rse-bash-advanced-exercises}

### Variables in shell scripts {#r-rse-bash-advanced-ex-script-variables}

In the `molecules` directory, imagine you have a shell script called `script.sh` containing the
following commands:

```shell
head -n $2 $1
tail -n $3 $1
```

While you are in the `molecules` directory, you type the following command:

```shell
bash script.sh '*.pdb' 1 1
```

Which of the following outputs would you expect to see?

1. All of the lines between the first and the last lines of each file ending in `.pdb`
    in the `molecules` directory
2. The first and the last line of each file ending in `.pdb` in the `molecules` directory
3. The first and the last line of each file in the `molecules` directory
4. An error because of the quotes around `*.pdb`

### Find the longest file with a given extension {#r-rse-bash-advanced-ex-longest-with-extension}

Write a shell script called `longest.sh` that takes the name of a
directory and a filename extension as its arguments, and prints
out the name of the file with the most lines in that directory
with that extension. For example:

```shell
$ bash longest.sh /tmp/data pdb
```

would print the name of the `.pdb` file in `/tmp/data` that has
the most lines.

### Script reading comprehension {#r-rse-bash-advanced-ex-reading-scripts}

For this question, consider the `data-shell/molecules` directory once again.
This contains a number of `.pdb` files in addition to any other files you
may have created.
Explain what each of the following three scripts would do when run as
`bash script1.sh *.pdb`, `bash script2.sh *.pdb`, and `bash script3.sh *.pdb` respectively.

```shell
# Script 1
echo *.*
```

```shell
# Script 2
for filename in $1 $2 $3
> do
>     cat $filename
> done
```

```shell
# Script 3
echo $@.pdb
```

### Using `grep` {#r-rse-bash-advanced-ex-using-grep}

Which command would result in the following output:

```text
and the presence of absence:
```

1. `grep "of" haiku.txt`
2. `grep -E "of" haiku.txt`
3. `grep -w "of" haiku.txt`
4. `grep -i "of" haiku.txt`

### Tracking a species {#r-rse-bash-advanced-ex-tracking-species}

Leah has several hundred
data files saved in one directory, each of which is formatted like this:

```text
2013-11-05,deer,5
2013-11-05,rabbit,22
2013-11-05,raccoon,7
2013-11-06,rabbit,19
2013-11-06,deer,2
```

She wants to write a shell script that takes a species as the first command-line argument
and a directory as the second argument. The script should return one file called `species.txt`
containing a list of dates and the number of that species seen on each date.
For example using the data shown above, `rabbit.txt` would contain:

```text
2013-11-05,22
2013-11-06,19
```

Put these commands and pipes in the right order to achieve this:

```shell
cut -d : -f 2
>
|
grep -w $1 -r $2
|
$1.txt
cut -d , -f 1,3
```

Hint: use `man grep` to look for how to grep text recursively in a directory
and `man cut` to select more than one field in a line.

An example of such a file is provided in `data-shell/data/animal-counts/animals.txt`

### Counting names {#r-rse-bash-advanced-ex-little-women}

You and your friend, having just finished reading *Little Women* by
Louisa May Alcott, are in an argument.  Of the four sisters in the
book, Jo, Meg, Beth, and Amy, your friend thinks that Jo was the
most mentioned.  You, however, are certain it was Amy.  Luckily, you
have a file `LittleWomen.txt` containing the full text of the novel
(`data-shell/writing/data/LittleWomen.txt`).
Using a `for` loop, how would you tabulate the number of times each
of the four sisters is mentioned?

Hint: one solution might employ
the commands `grep` and `wc` and a `|`, while another might utilize
`grep` options.
There is often more than one way to solve a programming task, so a
particular solution is usually chosen based on a combination of
yielding the correct result, elegance, readability, and speed.

### Matching and subtracting {#r-rse-bash-advanced-ex-match-subtract}

The `-v` option to `grep` inverts pattern matching, so that only lines
which do *not* match the pattern are printed. Given that, which of
the following commands will find all files in `/data` whose names
end in `s.txt` (e.g., `animals.txt` or `planets.txt`), but do
*not* contain the word `net`?
Once you have thought about your answer, you can test the commands in the `data-shell`
directory.

1.  `find data -name '*s.txt' | grep -v net`
2.  `find data -name *s.txt | grep -v net`
3.  `grep -v "temp" $(find data -name '*s.txt')`
4.  None of the above.

### `find` pipeline reading comprehension {#r-rse-bash-advanced-ex-reading-find}

Write a short explanatory comment for the following shell script:

```shell
wc -l $(find . -name '*.dat') | sort -n
```

### Finding files with different properties {#r-rse-bash-advanced-ex-find-properties}

The `find` command can be given several other criteria known as "tests"
to locate files with specific attributes, such as creation time, size,
permissions, or ownership.  Use `man find` to explore these, and then
write a single command to find all files in or below the current directory
that are owned by the user `ahmed` and were modified in the last 24 hours.

Hint 1: you will need to use three tests: `-type`, `-mtime`, and `-user`.

Hint 2: The value for `-mtime` will need to be negative—why?

### Combining options {#r-rse-bash-advanced-ex-combining-options}

In most command line tools,
multiple options can be combined with a single `-` and no spaces between the options:
`ls -F -a` is equivalent to `ls -Fa`.
FIXME: finish this exercise

### Other wildcards {#r-rse-bash-advanced-ex-other-wildcards}

FIXME: exercise to introduce ? and other wildcards.

## Key Points {#r-rse-bash-advanced-keypoints}

```{r, child="keypoints/rse-bash-advanced.md"}
```

```{r, child="./links.md"}
```
