# Project Structure {#r-rse-project}

```{r r-rse-project-setup, include=FALSE}
source("_common.R")
```

TODO: Restructure this to mimic/describe R package structure?

Project organization is like a diet:
everyone has one,
it's just a question of whether it's healthy or not.
In the case of a project,
"healthy" means that people can find what they need and do what they want without becoming frustrated.
This depends on two things:
how well organized the project is,
and how familiar people are with that style of organization.

As with coding style,
small pieces in predictable places with readable names are easier to find and use
than large chunks that vary from project to project
and have names like "stuff".
While we can be messy while we are working and then tidy up later,
experience teaches that we will be more productive if we make tidiness a habit
and put things in the right place right from the start.
This lesson therefore describes a widely-used template
for organizing small and medium-sized data analysis projects @Nobl2009.

> **Version First**
>
> This chapter assumes that a project's history and development is managed with Git,
> and that each project lives in a single repository.
> If you are organizing something messy,
> please start using version control before you make any changes
> so that you don't accidentally lose valuable work.

## What is a project? {#r-rse-project-thinking}

The first decision we have to make is what exactly constitutes a "project" @Wils2017.
Some examples are:

-   A dataset that is being used by several research projects.
    The project includes the raw data,
    the programs used to tidy that data,
    the tidied data,
    the extra files needed to make the dataset an R package (Chapter \@ref(r-rse-package-r)),
    and a few text files describing the data's authors, license, and [provenance][provenance].

-   A set of annual reports written for an [NGO][ngo].
    The project includes several Jupyter notebooks,
    some supporting Python libraries used by those notebooks,
    copies of the HTML and PDF versions of the reports,
    a text file containing links to the datasets used in the report
    (which can't be stored on GitHub since they contain personal identifying information),
    and a text file explaining details of the analysis that the authors didn't include in the reports themselves.

-   A software library that provides an interactive glossary of data science terms in both Python and R.
    The project contains the files needed to create a package in both languages,
    a Markdown file full of terms and definitions,
    and a Makefile with targets to check cross-references, compile packages, and so on.

More generally,
some common criteria for creating projects are one per publication,
one per deliverable piece of software,
or one per team.
The first tends to be too small:
a good dataset will result in several reports,
and the goal of some projects is to produce a steady stream of reports (such as monthly forecasts).
The second is a good fit for software engineering projects
whose primary aim is to produce tools rather than results,
but can be an awkward fit for data analysis work.
The third tends to be too large:
a team of half a dozen people may work on many different things at once,
and a repository that holds them all quickly looks like someone's basement.

The best rule of thumb for deciding what is and isn't a project
is to ask what people have meetings about.
If the same set of people need to get together on a regular basis to talk about something,
that "something" probably deserves its own repository.
And if the list of people changes slowly over time but the meetings continue,
that's an even stronger sign.

## What files should every project contain? {#r-rse-project-boilerplate}

Most projects' repositories contain four files.
Three of these are so widely used in open source software projects that GitHub provides support for them,
while the fourth is common in research work.
All of these files should be Markdown,
and will have a `.md` suffix (or no suffix at all),
and should use the principal names given in upper case
since a growing number of tools expect them.

-   `README.md` includes the project's title and a one-paragraph description of its purpose or content.
    GitHub displays the content of this file on the project's home page.

-   `LICENSE` (an expectation from CRAN) and `LICENSE.md` is the project's license (discussed in Chapter \@ref(r-rse-teams-license)).

-   `CODE_OF_CONDUCT.md` is its code of conduct (also discussed in Chapter \@ref(r-rse-teams-coc)).

-   `CITATION` explains how the work should be cited.
    This file should contains a plain text citation that can be copied and pasted into email,
    and may also include entries formatted for various bibliographic systems like [BibTeX][bibtex].

Other information may be included as sections in these files or put into files of their own:

-   `CONTRIBUTORS`
    lists everyone who has contributed to the project.
    Software projects often put this information in `README.md`,
    while research projects make it a section in `CITATION`.

-   `CONTRIBUTING.md`
    explains how to contribute,
    i.e.,
    what naming conventions to use for functions,
    what tags to put on issues (Section \@ref(r-rse-git-advanced-tag)),
    or how to install and configure the software needed to start work on the project.
    These instructions can also be included as a section in `README.md`;
    wherever they go,
    remember that the easier it is for people to get set up and contribute,
    the more likely they are to do so @Stei2014.

Even the four core files may seem like a lot,
but two of these (`LICENSE.md` and `CODE_OF_CONDUCT.md`) are usually chosen rather than written (Chapter \@ref(r-rse-teams-license))
and the others (`README.md` and `CITATION`) can be quite short to start with.
Having these files helps new contributors orient themselves,
and also signals that the project is well run.

What's more,
much of this content is [boilerplate][boilerplate],
i.e.,
the files are copied from one project to another without any changes.
Once someone knows that a project is using the MIT License (Section \@ref(r-rse-teams-software-license))
and the Contributor Covenant (Section \@ref(r-rse-teams-conduct)),
they don't need to read the files to know what's there.

## How should I structure the rest of my project? {#r-rse-project-organize}

@Nobl2009 described a way to organize small bioinformatics projects
that is equally useful for other kinds of research computing.
Each project is put in a separate Git repository,
and the directories in the root of this repository are organized according to purpose.
It specifies five top-level directories:

TODO: Redo for R projects as packages.

-   Raw data goes in in `./data-raw/` and is never modified after being stored.

-   Finally,
    documentation and manuscripts go in `./doc/`.

```{r project-noble, echo=FALSE, fig.cap="Project Layout"}
if (knitr::is_latex_output()) {
  knitr::include_graphics("figures/rse-project/noble.pdf")
} else {
  knitr::include_graphics("figures/rse-project/noble.svg")
}
```

Figure \@ref(fig:project-noble) below shows this layout for a project called `g-trans`.
A few things to notice are:

-   The documentation for the `regulate` script appears in the root of `./doc/`,
    while the paper for JCMB is stored in a subdirectory,
    since it contains several files.

-   There are several subdirectories underneath `./data/` ...

While the directories in the top level of each project are organized by purpose,
the directories within `./data/` .... are organized chronologically
to make it easy to see when data was gathered and when results were generated.
These directories all have names in [ISO date format][iso-date-format] like `YYYY-MM-DD`
to make it easy to sort them chronologically.
This naming is particularly helpful when data and results are used in several reports.

At all levels,
filenames are chosen so that they will be easy to match with simple shell wildcards.
For example,
a project might use <code><em>species</em>_<em>organ</em>_<em>treatment</em>.csv</code>
as a file-naming convention,
giving filenames like `gorilla_kidney_cm200.csv`.
This allows `gorilla_*_cm200.csv` to match all gorilla organs
or `*_kidney_*.csv` to match all kidney data.
It does produce long filenames,
but [tab completion][tab-completion] means that we only have to type the full name once.
Long filenames are just as easy to match in programs:
Python's `glob` and R's `Sys.glob` will both take a pattern and return a list of matching filenames.

@Marw2018 describes a simple layout:

```
├── DESCRIPTION
├── README.md
├── LICENSE
├── data
│   └── my_data.csv
└── vignette
    └── my_report.Rmd
```

The key differences are:

-   The `DESCRIPTION` file in the root directory contains
    the information needed to make the project an R package (Chapter \@ref(r-rse-package-r)).

## How should I manage a mix of compiled programs and scripts? {#r-rse-project-scripts}

Programming languages come in two flavors: compiled and interpreted.
In order to run a program in a [compiled language][compiled-language] such as C++ or Java,
we give the source files to a [compiler][compiler]
that translates them into instructions a computer can actually execute
and saves those instructions in files (Figure \@ref(fig:r-rse-project-languages)a).
Those files full of instructions can then be re-used as often as we want.
If we are using an [interpreted language][interpreted-language] like R,
on the other hand,
we give our source files to an [interpreter][interpeter].
It also translates the code into instructions,
but puts those instructions in memory and executes them immediately (Figure \@ref(fig:r-rse-project-languages)b).

```{r r-rse-project-languages, echo=FALSE, fig.cap="Language Types"}
knitr::include_graphics("figures/FIXME.png")
```

Saving instructions in files versus executing them immediately may seem like a small difference,
but historically it led to very different styles of programming.
Compiled languages usually ran faster than interpreted languages,
but compilation took time,
so interpreted languages were better for [exploratory programming][exploratory-programming].
The differences are much smaller these days than they were twenty years ago,
but we do still tend to use compiled languages for anything that has to interact directly with hardware
and then [wrap][wrap-code] those libraries for use in interpreted languages.

All of this is preamble to deciding where to put things if a project contains compiled programs.
Most software engineers put source code in version control
and recompile it as needed to produce executables:

1.  It saves disk space.

2.  Version control tools can't diff or merge a compiled program.

3.  Compiled programs are much more sensitive to small differences
    between operating system versions and external dependencies
    than interpreted programs,
    so something compiled on one computer might not work on another anyway.

As always,
the approach matters less than being consistent
and including a note in `CONTRIBUTING` or elsewhere to document the decision.

## How should I document the software in a project? {#r-rse-project-software-docs}

An old proverb says, "Trust, but verify."
The equivalent in programming is, "Be clear, but document."
No matter how well software is written,
it always embodies decisions that aren't explicit in the final code
or accommodates complications that aren't going to be obvious to the next reader.
Putting it another way,
the best function names in the world aren't going to answer the questions
"Why does the software do this?"
and
"Why doesn't it do this in a simpler way?"
This lesson will explore who we should write documentation for,
what we should write for them,
and where it should go.

Noble's layout places documentation and manuscripts in `./docs/`.
We recommend separating these into `./docs/` and `./reports/`:

1.  Most projects generate the documentation for their software directly from the source code
    (Chapters \@ref(r-rse-package-r) and \@ref(r-rse-package-py)).
    Putting these files in the same directory as handwritten files
    has the same problems as putting a compiler's output in the same directory as handwritten scripts.
    In fact,
    it's often worse,
    since [documentation generators][documentation-generator] often create many subdirectories and support files.

2.  We often create several reports for a single project,
    which complicates file management even further.

There are three kinds of people in any domain:
[novices][novice],
[competent practitioners][competent-practitioner],
and [experts][expert] @Wils2018.
A novice doesn't yet have a [mental model][mental-model] of the domain;
they don't know what the key terms are,
how they relate,
what the causes of their problems are,
or how to tell whether a solution to their problem is appropriate or not.

Competent practitioners know enough to accomplish routine tasks with routine effort:
they may need to check [Stack Overflow][stack-overflow] every few minutes,
but they know what to search for and what "done" looks like.
Finally,
experts have such a deep and broad understanding of the domain
that they can solve routine problems at a glance
and are able to handle the one-in-a-thousand cases
that would baffle the merely competent.

Each of these three groups needs a different kind of documentation.
A novice needs a tutorial that introduces her to key ideas one by one
and shows how they fit together.
A competent practitioner needs reference guides, cookbooks, and Q&A sites;
these give her solutions close enough to what she needs
that she can tweak them the rest of the way.
Experts need this material as well—nobody's memory is perfect—but
they may also paradoxically want tutorials.
The difference between them and novices is that experts want tutorials on how things work
and why they were designed that way.

The first thing to decide when writing documentation
is therefore to decide which of these needs we are trying to meet.
Tutorials like this one should be long-form prose that contain code samples and diagrams.
They should use [authentic tasks][authentic-task] to motivate ideas,
i.e.,
show people things they actually want to do rather than printing the numbers from 1 to 10,
and should include regular check-ins
so that learners and instructors alike can tell if they're making progress.

Tutorials help novices build a mental model,
but competent practitioners and experts will be frustrated by their slow pace and low information density.
They will want single-point solutions to specific problems like
how to find cells in a spreadsheet that contain a certain string
or how to configure the web server to load an access control module.
They can make use of an alphabetical list of the functions in a library,
but are much happier if they can search by keyword to find what they need;
one of the signs that someone is no longer a novice is that
they're able to compose useful queries and tell if the results are on the right track or not.

That observation brings us to the notion of a [false beginner][false-beginner],
which is someone who appears not to know anything,
but who has enough prior experience in other domains
to be able to piece things together much more quickly than a genuine novice.
Someone who is proficient with MATLAB, for example,
will speed through a tutorial on Python's numerical libraries
much more quickly than someone who has never programmed before.

In an ideal world,
we would satisfy these needs with a [chorus of explanations][caulfield-chorus],
some long and detailed,
others short and to the point.
In our world, though,
time and resources are limited,
so all but the most popular packages must make do with single explanations.
The rest of this section will therefore look at
how to create reference guides and FAQs.

## What should I document? {#r-rse-project-infer}

The answer to the question in this section's title depends on what stage of development we are in.
If we are doing [exploratory programming][exploratory-programming],
a short docstring to remind ourselves of each function's purpose is good enough.
(In fact, it's probably better than what most people do.)
That one- or two-liner should begin with an active verb and describe either
how inputs are turned into outputs,
or what side effects the function has;
as we discuss below,
if we need to describe both,
we should probably rewrite our function.

An active verb is something like "extract", "normalize", or "find".
For example,
these are all good one-line docstrings:

-   "Create a list of current ages from a list of birth dates."
-   "Clip signals to lie in [0...1]."
-   "Reduce the red component of each pixel."

We can tell our one-liners are useful if we can read them aloud in the order the functions are called
in place of the function's name and parameters.

Once we start writing code for other people—including ourselves three months from now—our
docstrings should describe:

1.  The name and purpose of every public class, function, and constant in our code.
2.  The name, purpose, and default value (if any) of every parameter to every function.
3.  Any side effects the function has.
4.  The type of value returned by every function.
5.  What exceptions those functions can raise and when.

The word "public" in the first rule is important.
We don't have to write full documentation for helper functions
that are only used inside our package and aren't meant to be called by users,
but these should still have at least a comment explaining their purpose.
We also don't have to document unit testing functions:
as discussed in Chapter \@ref(r-rse-correct),
these should have long names that describe what they're checking
so that failure reports are easy to scan.

## How can I create a useful FAQ? {#r-rse-project-faq}

An [FAQ][faq] is a list of frequently-asked questions and corresponding answers.
A good FAQ uses the terms and concepts that people bring to the software
rather than the vocabulary of its authors;
putting it another way,
the questions should be things that people might search for online,
and the answers should give them enough information to solve their problem.

Creating and maintaining a FAQ is a lot of work,
and unless the community is large and active,
a lot of that effort may turn out to be wasted,
because it's hard for the authors or maintainers of a piece of software
to anticipate what newcomers will be mystified by.
A better approach is to leverage sites like [Stack Overflow][stack-overflow],
which is where most programmers are going to look for answers anyway:

1.  Post every question that someone actually asks us,
    whether it's online, by email, or in person.
    Be sure to include the name of the software package in the question
    so that it's findable.
2.  Answer the question,
    making sure to mention which version of the software we're talking about
    (so that people can easily spot and discard stale answers in the future).

With a bit of work,
the [Stack Exchange Data Explorer][stack-exchange-data-explorer]
can be used to download questions and answers about our software
if we want to put them all in an offline guide.
we can also use [Stack Printer][stack-printer] for this;
for example, the URL
<http://www.stackprinter.com/topvoted?service=stackoverflow&tagged=rstudio>
will bring up a paged view of top-voted questions about RStudio.

[Stack Overflow][stack-overflow]'s guide to [asking a good question][stack-overflow-good-question]
has been refined over many years,
and is a good guide for any project:

Write the most specific title we can.

Give context before giving sample code.
:   A few sentences to explain what are are trying to do and why
    will help people determine if their question is a close match to ours or not.

Provide a minimal reprex.
:   Section \@ref(r-rse-teams-bugs) explains the value of a [reproducible example][reprex] (reprex),
    and why reprexes should be as short as possible.
    TODO: Discuss reprex package.
    Readers will have a much easier time figuring out if this question and its answers are for them
    if they can see *and understand* a few lines of code.

Tag, tag, tag.
:   Keywords make everything more findable,
    from scientific papers and left-handed musical instruments
    to solutions for programming problems.

Use "I" and question words (how/what/when/where/why).
:   The section headings in these lessons follow this rule for the same reason that questions in a FAQ should:
    writing this way forces us to think more clearly about
    what someone might actually be thinking when they need help.

Keep each item short.
:   The "minimal manual" approach to instructional design @Carr2014
    breaks everything down into single-page steps,
    with half of that page devoted to troubleshooting.
    This may feel like baby steps to the person doing the writing,
    but is often as much as a person searching and reading can handle.
    It also helps writers realize just how much implicit knowledge they are assuming.

Allow for a [chorus of explanations][caulfield-chorus].
:   As discussed earlier,
    users are all different from one another,
    and are therefore best served by a chorus of explanations.
    Do not be afraid of providing multiple explanations to a single question
    that suggest different approaches
    or are written for different prior levels of understanding.

## How does documentation for data differ from documentation for code? {#r-rse-project-data-vs-code}

Documenting data is different from code
because there's rarely an element of time within code documentation:
we we describe what is there,
not how it came to be.
Data,
on the other hand,
always comes from somewhere and has (almost always) had something done to it.
Its documentation must therefore include details about process,
selection,
and transformation.

Often,
all we need to document data is short action statements to describe the actions taken.
Depending on the complexity,
the content description and the process information may be contained in the same statement.

However,
a file that has recieved extensive manual editing and curation
should have much more detailed description of what was done.
Good tools,
like [OpenRefine][openrefine],
allow us to export a list of all the changes we have made to a file.
This is extremely detailed process information,
much like looking at a lenthy series of diffs in version control history,
but these change lists do not include *why* these changes were made.
(Some of this may be in version control commit messages,
but there may be many changes within a single commit.)
For example,
documenting that we changed all values like "[1980?]", "1980?", and "[[1980]" to "1980" is not enough:
the question of "What happened here?" as been answered,
but now *why*.
Both pieces must be present for full understanding.

## How should I document the data in a project? {#r-rse-project-data-docs}

To answer the question in this section's title,
think about the questions we would have playing a text adventure game
in which we wake up in a room we don't recognize.
We would ask things like:
Where am I?
What's around me?
What can I do here?
Where can I go?
We need to know that things exist before we can go investigate them,
and the same goes for making our way around data.

This is why documentation starts with a README file and a short abstract for the project:
they are where most newcomers will start building their expectations around the data.  
At a minimum,
we need to answer questions about content and time.
Documentation about content should start
with what is available and where things have gone.
Newcomers will generally drill down from:

-   Project: what did we do?
-   Dataset: what did we make?
-   Data files: what's in this file or that column?
-   Datum: where did this value come from?

Discussions about what should go into documentation about data will often begin with the end game
and ask authors to report absolutely *everything* that has happened to the data.
However,
the better place to start would be with *anything*.  
Anything is better than nothing and is a useful starting point:
improving from something is easier and less daunting than trying to write everything.
While a project's documentation will become more complex over time,
the most important requirement at every stage is sustainability:
we must design requirements that are still feasible,
and still collect useful information,
even during crunch times.

Multiple styles of material will help different people best (Section \@ref(r-rse-project-faq)),
but most projects do not have the resources to do this.
More details are great to have in documentation,
but asking for too much risks burnout and no documentation at all.
The rules to live by when deciding what should go in are:

1.  Documentation should have enough information,
2.  about the project, methods, and materials
3.  such that the information is maintainable over time,
4.  in an accessible format,
5.  and valuable for those who need it.

Breaking this down:

-   "Enough information" means that some information can always be safely omitted.
    For example,
    some methods or computations are best described in published papers;
    unless those papers are locked behind paywalls,
    we can link to them instead of duplicating their content.

-   "About the project, methods, and materials"
    are the elements of most projects that we need to describe.
    Just like a personal introduction should have our name, pronouns, and position,
    we should introduce our data by explaining what the project was for,
    what methods we used in int,
    and what materials we applied those methods to.

-   "Maintainable" reflects the fact that active projects outgrow static documentation.
    Since an out-of-date description can be more misleading than no description at all,
    we should construct documentation in ways that ensure everyone can contribute
    without it being burdensome.

-   "Accessible format" means two things.
    First,
    proprietary formats create barriers to access,
    since some people may not have access to the software needed to read the documents.
    They also shorten those documents' useful lifespan,
    since manufacturers can change those formats over time.
    If we do use such a format because we have to integrate with particular systems
    or because formatting and image embedding are better,
    we should always make a plain-text copy available as well.

    The other meaning is accessible to all people.
    We should use proper markup so screen readers can interact with the structure of the text,
    provide transcripts for all screencasts or other videos,
    add alt-text descriptions to images,
    and ensure that all text is actually rendered so that it can be selected and interacted with.
    The UK Home Office has published a [set of posters][ukho-accessibility] that summarize accessibility guidelines
    and also serve as a great checklist for ensuring access.

-   Finally,
    "for those who need it" means taking your audience into account
    when prioritizing what to include and at what level of detail.
    For example,
    the documentation for a specialized bioinformatics package could reasonably expect readers to have
    a graduate-level understanding of the topic,
    so documentation aimed at high school students may simply not be worth creating.

> **Your Future Self Will Thank You**
>
> Documentation is often promoted for the good of people reusing data who were not part of creating the data in the first place.
> Prioritizing their needs can be difficult:
> how can we justify spending time for other people
> when our current projects need work fo the good of the people working on them right now?
>
> Instead of thinking about people who are unknown and unrelated,
> we can think about newcomers to our team
> and the time we will save *ourselves* in onboarding them.
> We can also think about the time we will save ourselves
> when we come back to this project five months or five years from now.
> Documentation that serves these two groups well
> will almost certainly serve the needs of strangers as well.

These additional rules are taken from [@Good2014,@Mich2015,@Hart2016,@Zook2017]:

-   **Keep raw data raw.**
    Exactly what constitutes "raw" data isn't always clear:
    raw data may be the data you downloaded from a repository,
    or it may come directly from field observations or hardware.
    Either way,
    retaining an unchanged version is important for reproducibility,
    and in case you accidentally overwrite your working copy.

    The analog inputs to a voltmeter probably don't need to be recorded on tape
    if we have the voltmeter's digitized output.
    However,
    our analysis methods and tools can change over time,
    and even after years of work they can contain bugs.
    We should therefore keep the original data exactly as we received it
    so that we can re-do previous analyses or try new ones.
    This is also a good safeguard if anyone ever questions the integrity of the research:
    it will be hard to defend ourselves against accusations of fraud
    if we can't show our work.

-   **Give every part of the data a unique identifier.**
    To aid reproducibility (and save a lot of confusion in conversation),
    it should be possible to uniquely identify every part of every dataset.
    This doesn't mean every cell has to have a unique ID;
    instead,
    every datum should have an "address" or location description that can uniquely identify it.
    For example,
    a datum may be "in file `ACX-02.csv`, under column `reading_type`, in row 450".

    To achieve this,
    the dataset itself should have a [DOI][doi] (Section \@ref(r-rse-publish-identifiers)),
    and within the dataset,
    every file should have a meaningful name (Section \@ref(r-rse-project-data-vs-code)).
    Going further,
    every record should have a unique [key][key] within the dataset (Section \@ref(r-rse-publish-data)):
    row numbers can change as datasets are sorted,
    but unique keys that are part of records should always stay in those records.

-   **Have a backup plan.**
    Every hard drive eventually fails;
    the hardware needed to read various storage media eventually becomes unavailable,
    and there is always the risk that bankruptcy, corporate merger, or a court order
    will shut down the site we've been using to store our data.
    We should therefore always have a second copy in a different physical and jurisdictional locational.
    If the primary store is GitHub,
    copy the data to a secondary online storage provider
    or onto a USB drive and take it home.
    If the data contains sensitive information such as personal health records,
    you must ensure that the storage complies with data privacy regulations
    and that the data is properly anonymized before it is uploaded to an off-site storage location.

    Before doing any of this, though,
    ask your department or institution what facilities they provide.
    Many academic institutions have some form of institutional repository
    that data can be uploaded to
    or a unit whose job it is to handle long term data storage requests.
    Their staff will also be more familiar with data privacy regulations than most researchers.

-   **Test that the backups work.**
    It's hard to find out how often backups fail—many statistics are inflated
    by companies selling backup tools—but figures of 15%–25% are often quoted.
    Restoration failures are particularly common after adding new datasets,
    changing backup software or procedures,
    moving to new hardware or new backup locations,
    or just because it's Tuesday.
    We should therefore periodically check that backups can actually be restored,
    and in particular,
    that they can be restored by someone other than the person who created them
    (so that if a password is required,
    someone else knows what it is).

## How can I get started documenting my data? {#r-rse-project-data-start}

Writing anything can be difficult,
and documentation is no different.
Setting up places for information to be housed both formally and informally is the first step;
creating a checklist should be the second.

The data used within an active project is often rapidly changed, added, or removed.
Maintaining and collecting relevant documentation within this phase of constant change can be difficult.
One way to tackle this is to keep informal documentation.
Creating a [parking lot][parking-lot] file for each dataset
provides a place to jot down notes when things happen.
These documents should be the home for quick notes,
important links,
and any other piece of information we aren't yet sure what to do with.
This takes off the pressure of trying to write formally and well,
and avoids the decision fatigue of trying to figure out exactly where everything should go
while we're trying to do something else.

Screenshots can also be a quick way to grab a bunch of metadata at once.
Whenever we download data from a repository,
we can take a screenshot of the landing page we downloaded it from and save the URL (or suggested citation) to the notes file.
Any website where we have to fill in query fields,
ranges,
or other information to get a result
is a perfect candidate for a screenshot.

A second strategy for dealing with change in active projects is
to create a to-do list and assign responsibilities,
either as a file in the project's repository
or as a set of tasks in its issue tracking system (Section \@ref(r-rse-teams-issues)).
"Just write documentation" is a large ask of anyone without boundaries or a clear end;
like any other element of a research project,
establishing a clear scope of work and responsibilities is essential.

## What data documentation should I create first? {#r-rse-project-data-first}

The first thing to produce when docmenting data is an inventory of what data is available.
This inventory collects important informaion for the team during the active collection and analysis process.  

We start with a bulleted outline of our data collection points.
This is different for every domain,
but always describes the phases or points within the project that data is collected or produced.
For example,
a longitudinal study may collect data from subjects during intake and every three weeks following.

Using that list,
we can fill in the data products being collected in each interaction.
The data points being collected are less important than
the named instruments, inventories, samples, and so on being collected during each phase.
For example,
"participant demographic sheet version April 2019"
might be all that our team needs.

Some of this information may already be available in
the detailed descriptions of data collection in project proposals or human subjects review documentation,
so the data inventory can start as
a bulleted list of these data products with extra notes.
The bullet names can be short,
but should be meaningful to the team.
This can serve as a starting point for describing information already collected
and provide a placeholder for work yet to be completed.

The following questions should be answered for each data product,
but can be answered in any order:

-   Where are any physical representations of this data stored?
    This is relevant for anything with surveys, samples, specimines, interview sheets, etc.
-   Where are any digital representations of this data stored
    and what are their file names?  
-   Are there any caveats to data collection for this piece of data?
    Note the details and timeframe for any changes to data collection methods,
    formatting differences,
    or any other detail that may make this part of the different or surprising in comparison to the others.

The next task is to think about the possible sections of documentation
and create a list of relevant sections needed.  
One problem with general guides is the number of possible sections needed across all domains.
Not every section is relevant or valuable for each project,
so each team or lab should create its own template for data documentation.
This should combine the elements commonly used within their domain and required by their institutions and funders.
Each project may then customize the field further
and change its customization over time,
but this way all the documentation will be similar.

This template should be a list of sections
with relevant boilerplate text when that makes sense.
For example,
a lab may have a standard license,
contributors' guide,
and code of conduct.
This template should be stored under version control so proposed changes can be discussed
and changes that are made can be tracked over time.

## How should I manage data that can't be stored in version control? {#r-rse-project-external}

Small datasets that don't contain sensitive information should be stored in version control:
as a rule of thumb,
anything you would send as an email attachment is probably small enough to be put into Git,
while anything that might reveal someone's identity should not be.
If data is large or sensitive,
there should still be something in `./data/` to show its existence,
and that "something" should be easy for programs to read.
One option is a CSV file whose columns are:

-   the name of the dataset,
-   its URL or other unique identifier,
-   the date it was last checked, and
-   its size (so that users will have some idea of how much work is involved in processing it).

Another option is to have one file per dataset,
so that instead of reading `gorilla_genome.bam`,
the program reads `gorilla_genome.yml` and then uses the `url` key in that file to find the data it actually wants.
Whatever you do,
you should always include a `README.md` file in `./data/`
that documents the [provenance][provenance] and organization of the data
(Section \@ref(r-rse-publish-data)).

## Summary {#r-rse-project-summary}

FIXME: create concept map for project structure

## Exercises

The exercises explore the dataset from @Meil2015
and try to understand the relationship between the study and the included files.
Go to the dataset's page (http://doi.org/10.3886/E17507V2) and download the files.
You will need to make an ICPSER account and agree to their data agreement before you can download.

See @Wick2016. FIXME where should this citation go?

### Understand a project {#r-rse-project-ex-understand-project}

Review the dataset's main page to get a sense of the study.
Review the spreadsheet file and the coded response file.
Answer the following questions:

1.  Who are the participants of this study?
2.  What types of data was collected and used for analysis?
3.  Can you find information on the demographics of the interviewees?
4.  This dataset is clearly in support of an article.
    What information can you find about it, and can you find a link to it?

### Determining the audience for documentation {#r-rse-project-ex-audience}

The first step to creting documentation is to think about the audience over time.
Not every potential user of the documentation will need it in the short term,
so starting with the most immediate users provides some strategic planning for time.  

Below is a grid of potential audiences and timeframes.
These groups are generic and should be adjusted as needed for your project's domain.
For example,
some geology and climate data are meant to be preserved for decades,
while other projects only have a useful lifespan of a few years.

For each potential audience group,
mark each box to indicate if that audience group would be in need of the data and in which timeframes.
You can repeat marks in each column and row as needed.
You may also want to use several types of marks to indicate certainty or uncertainty.

| Currently | Within the next 2 years | 2-5 years from now | 5+ years | Audience                        |
|-----------|-------------------------|--------------------|----------|---------------------------------|
|           |                         |                    |          | Just me                         |
|           |                         |                    |          | My project advisor or PI        |
|           |                         |                    |          | Others in my project team       |
|           |                         |                    |          | My lab or department members    |
|           |                         |                    |          | Researchers in my field         |
|           |                         |                    |          | Researchers outside of my field |
|           |                         |                    |          | Publication reviewers           |
|           |                         |                    |          | Federal or government agency    |
|           |                         |                    |          |                                 |
|           |                         |                    |          |                                 |

### Creating documentation template {#r-rse-project-ex-create-doc-template}

Below is a list of sections and subsections that are generally useful across many domains.
Start with this list and edit to remove, add, or edit sections that would be relevant to your team or project.
You may also wish to print this out and pass this around to your group members to fill out independently
and have a facilitator gather and synthesize the results.
A blank section is at the end to encourage you to add your own information.
Additional notes and other metadata could be added to each section to assign a specific person to write that section,
collect up the information for it, etc.

-   Administrative and personnel details:
    -   Authors, principle investigators, contributors, etc.,
        with associated institutions, contact information, and other identifiers
    -   Description of project team
    -   Associated papers, code, talks, datasets, etc.
    -   Funders and grant numbers
-   Data licensing information
    -   Suggested citation
    -   Who to contact if there are any questions
-   Project information:
    -   Brief description of the dataset and/or abstract, including relevant collection and processing dates
    -   Collection methods, including dates of collection, data processing, etc.
    -   Names, model numbers, and calibration information for any instruments used during data collection
    -   Description of scripts (e.g. R, Python, MATLAB, etc.) and their purpose
    -   Data processing workflow and stages
    -   Data cleaning process
    -   De-identification or other data scrubbing steps that occurred
-   Data file information (repeat for each file as needed):
    -   List of files to be included, grouped in meaningful units
    -   Number of rows, fields, columns, etc.
    -   Description of folder contents and/or of large groups of similar files
    -   Explanation of formats and required software to read them
    -   Languages represented within your data
    -   Description of the values, units, etc. for each column or field (codebook)
    -   Description of columns and fields in the data files (data dictionary)
    -   Other domain specific descriptive information
-   Other (add sections as desired)

### Making permanent links {#r-rse-project-ex-permanent-links}

The link to the UK Home Office's [accessibility guideline posters][ukho-accessibility] might change in future.
Use the [Wayback Machine][wayback-machine] to find a link that is more likely to be usable in the long run.

## Key Points {#r-rse-project-keypoints}

```{r, child="keypoints/rse-project.md"}
```
