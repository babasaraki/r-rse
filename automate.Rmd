# Automating Analyses {#r-rse-automate}

```{r r-rse-automate-setup, include=FALSE}
source("_common.R")
```

TODO: Not sure how to use this in the context of R package development/software engineering... May not need this chapter since R has enough tools to do these tasks.
TODO: Maybe instead of Makefile, this chapter cover drake instead? Its much easier than Make, and works better within R's framework.

It's easy to run one program to process a single data file,
but what happens when our analysis depends on many files,
or when we need to re-do the analysis every time new data arrives?
What should we do if the analysis has several steps
that we have to do in a particular order?

If we try to keep track of this ourselves,
we will inevitably forget some crucial steps,
and it will be hard for other people to pick up our work.
Instead,
we should use a [build tool][build-tool]
to keep track of what depends on what
and run our analysis programs automatically.
These tools were invented to help programmers rebuild complex software,
but can be used to automate any workflow.

As a running example,
we will look at the distribution of word frequencies in classic English novels.
[Zipf's Law][zipfs-law] states that
the second most common word in a body of text appears half as often as the most common,
the third most common appears a third as often,
and so on.
To test it,
we will use these works from [Project Gutenberg][gutenberg]:

| Book                            | Length (words) |
| ------------------------------- | -------------: |
| anne_of_green_gables.txt        |         105642 |
| common_sense.txt                |          24999 |
| count_of_monte_cristo.txt       |         464226 |
| dracula.txt                     |         164424 |
| emma.txt                        |         160458 |
| ethan_frome.txt                 |          37732 |
| frankenstein.txt                |          78098 |
| jane_eyre.txt                   |         188455 |
| life_of_frederick_douglass.txt  |          43789 |
| moby_dick.txt                   |         215830 |
| mysterious_affair_at_styles.txt |          59604 |
| pride_and_prejudice.txt         |         124974 |
| sense_and_sensibility.txt       |         121590 |
| sherlock_holmes.txt             |         107533 |
| time_machine.txt                |          35524 |
| treasure_island.txt             |          71616 |

The most common words in this [corpus][corpus] appear this many times:

| Word | Count |
| ---- | ----: |
| the  | 97278 |
| and  | 59385 |
| to   | 56028 |
| of   | 55190 |
| I    | 45680 |
| a    | 40483 |
| in   | 30030 |
| was  | 24512 |
| that | 24386 |
| you  | 22123 |
| it   | 21420 |

The frequencies don't match Zipf's predictions exactly—for example,
we would expect about 48,600 occurrences of "and"—but
there certainly seems to be a decay curve of some kind.

Our goals are:

1.  Analyze one input file to see how well it conforms to Zipf's Law.
2.  Analyze multiple input files to see how well they conform in aggregate.
3.  Plot individual and aggregate word frequency distributions and their expected values.

Our starting point is:

1.  The books are text files in the `data/` directory.
TODO: number 2 doesn't make sense for R. We don't really pipe stuff from the shell.
2.  `...` reads a text file and creates a CSV file with two columns:
    a word and how many times the word occurs.
    We can analyze several files at once by [piping][pipe-unix] them into the program
    using something like `cat data/*.txt | ...`.
    (If you don't know what this means,
    now would be a good time to review the material on the Unix shell
    in Chapters \@ref(r-rse-bash-basics) and \@ref(r-rse-bash-advanced)).
3.  `...` takes one or more of these two-column CSV files as input
    and sums the counts for all occurrences of each word.
4.  `...` creates a plot that shows word rankings on the X axis
    and word counts on the Y axis.
5.  `...` compares actual distributions against theory
    and give a fitting score.

We will use a program called [Make][make] to automate our analysis
so that every time we add a new book to our data,
we can create new plots and update our fits with a single command.
Make works as follows:

1.  Every time the [operating system][operating-system] creates, reads, or changes a file,
    it updates a [timestamp][timestamp] on the file to show when the operation took place.
    Make can compare these timestamps to figure out whether files are newer or older than one another.

2.  A user can describe which files depend on each other
    by writing [rules][rule-make] in a [Makefile][makefile].
    For example,
    one rule could say that `results/moby_dick.csv` depends on `data/moby_dick.txt`,
    while another could say that the plot `results/comparison.png`
    depends on all of the CSV files in the `results` directory.

3.  Each rule also tells Make how to update an out-of-date file.
    For example,
    the rule for *Moby Dick* could tell Make to run `...`
    if the result file is older than either the raw data file or the program.

4.  When the user runs Make,
    the program checks all of the rules in the Makefile
    and runs the commands needed to update any that are out of date.
    If there are [transitive dependencies][transitive-dependency]—i.e.,
    if A depends on B and B depends on C—then Make will trace them through
    and run all of the commands it needs to in the right order.

> **Alternatives to Make**
>
> The first version of Make was written in 1976.
> Programmers have created many replacements for it in the decades since then—so many,
> in fact,
> that none have attracted enough users to displace it.
> If you would like to explore them,
> check out [drake][drake] for R.
> If you want to go deeper,
> [@Smit2011] describes the design and implementation of several build tools.

### Setting Up

This chapter uses a version of Make called [GNU Make][gnu-make].
It comes with MacOS and Linux,
and you can install it on Windows using [Chocolatey][chocolatey]:

```shell
$ choco install make
```

### Acknowledgements

This chapter is based on the [Software Carpentry lesson on Make][swc-make]
maintained by [Gerard Capes][capes-gerard]
and on [Jonathan Dursi][dursi-jonathan]'s
[introduction to pattern rules][dursi-pattern-rules].

## How can I update a single file using Make? {#r-rse-automate-single-file}

To start,
let's create a file called `Makefile` in the root of our project:

```make
# Regenerate results for "Moby Dick"
results/moby_dick.csv : data/moby_dick.txt
        python bin/countwords.py data/moby_dick.txt > results/moby_dick.csv
```

As in the shell and many other programming languages,
`#` indicates that the first line is a comment.
The second and third lines form a [rule][rule-make]:
the [target][target-make] of the rule is `results/moby_dick.csv`,
its single [prerequisite][prerequisite-make] is the file `data/moby_dick.txt`,
and the two are separated by a single colon `:`.

The target and prerequisite tell Make what depends on what;
the indented line below them describes the [action][action-make] needed
to update the target if it is out of date.
The action can be one or more shell commands,
but each command *must* be indented by a single tab character:
we can't use spaces or a mix of spaces and tabs.
In this rule,
the action is "run `bin/countwords.py` on the raw data file
and put the output in a CSV file in the `results` directory".

To test our rule, run this command in the shell:

```shell
$ make
```

Make automatically looks for a file called `Makefile`
and follows the rules it contains.
In this case,
one of three things will happen:

1.  If `results/moby_dick.csv` doesn't exist,
    Make runs the action to create it.
2.  If `data/moby_dick.txt` is newer than `results/moby_dick.csv`,
    Make runs the action to update the results.
3.  If `results/moby_dick.csv` is newer than its prerequisite,
    Make does nothing.

In the first two cases,
Make prints the commands it runs
along with anything those command prints to the screen
via [standard output][stdout] or [standard error][stderr].
There is no screen output in this case,
so we only see the command.

> **Indentation Errors**
>
> If a `Makefile` indents a rule with spaces rather than tabs,
> Make produces an error message like this:
>
> ```text
> Makefile:3: *** missing separator.  Stop.
> ```

No matter what happened the first time we ran `make`,
if we run it again right away it does nothing
because our rule's target is now up to date.
It tells us this by displaying the message:

```text
make: `results/moby_dick.csv' is up to date.
```

We can check that it is telling the truth by listing the files with their timestamps,
ordered by how recently they have been updated:

```shell
$ ls -l -t data/moby_dick.txt results/moby_dick.csv
```

```text
-rw-r--r--  1 hamilton  staff   219107 31 Dec 08:58 results/moby_dick.csv
-rw-r--r--  1 hamilton  staff  1276201 31 Dec 08:58 data/moby_dick.txt
```

As a further test:

1.  Delete `results/moby_dick.csv` and run `make` again (case #1);
    Make runs the action.
2.  Use `touch data/moby_dick.txt` to update the timestamp on the data file,
    then run `make` (case #2).
    Again,
    Make runs the action.

## How can I manage multiple files? {#r-rse-automate-multiple}

Our Makefile isn't particularly helpful so far,
though it *does* already document exactly how to reproduce one specific result.
Let's add another rule to it:

```make
# Regenerate results for "Moby Dick"
results/moby_dick.csv : data/moby_dick.txt
        python bin/countwords.py data/moby_dick.txt > results/moby_dick.csv

# Regenerate results for "Jane Eyre"
results/jane_eyre.csv : data/jane_eyre.txt
        python bin/countwords.py data/jane_eyre.txt > results/jane_eyre.csv
```

When we run `make` it tells us:

```text
make: `results/moby_dick.csv' is up to date.
```

By default Make only attempts to update the first target it finds in the Makefile,
which is called the [default target][default-target-make].
In this case,
the first target is `results/moby_dick.csv`,
which is already up to date.
To update something else,
we need to tell Make specifically what we want:

```shell
$ make results/jane_eyre.csv
```

```text
python bin/countwords.py data/jane_eyre.txt > results/jane_eyre.csv
```

## How can I update several files at once? {#r-rse-automate-phony}

If we have to run `make` once for each result
we're right back where we started.
However,
we can add a rule to our Makefile to update all of our results at once.
The key is to create a [phony target][phony-target-make]
that doesn't correspond to an actual file.
Let's add this line to the top of our Makefile:

```make
all : results/moby_dick.csv results/jane_eyre.csv
```

There is no file called `all`,
and this rule doesn't have any actions of its own,
but when we run `make all`,
it creates a list of the things `all` depends on,
then brings each of those prerequisites up to date (Figure \@ref(fig:automate-all)).

```{r automate-all, echo=FALSE, fig.cap="Making Everything"}
knitr::include_graphics("figures/FIXME.png")
```

As this diagram shows,
the order in which rules appear in the Makefile
does not necessarily determine the order in which actions are run.
Make is free to run commands in any order
so long as nothing is updated before its prerequisites are up to date.
This is called [declarative programming][declarative-programming]:
we declare what outcome we want
and the program figures out how to achieve it.

We can use phony targets to automate and document all of the tasks in our work.
For example,
let's add another target to our Makefile to delete all of the result files we have generated
so that we can start afresh.
By convention this target is called `clean`,
and ours looks like this:

```make
# Remove all generated files.
clean :
        rm -f results/*
```

The `-f` flag to `rm` means "force removal":
when we use it,
`rm` won't complain if the files we have told it to remove are already gone.
If we now run:

```shell
$ make clean
```

Make will delete any results files we have.
This is a lot safer than typing `rm -f results/*` at the command-line,
because if we mistakenly put a space after the `/`
and delete all of the files in the project's root directory,
we'll only make the mistake once.

Phony targets are very useful,
but there is a catch.
Try doing this:

```shell
$ mkdir clean
$ make clean
```

```text
make: `clean' is up to date.
```

Since there is a directory called `clean`,
Make thinks the target `clean` in the Makefile refers to this directory.
Since the rule has no prerequisites,
it can't be out of date,
so no actions are executed.

We can unconfuse Make by putting this line at the top of Makefile
to tell it explicitly which targets are phony:

```make
.PHONY : all clean
```

## How can I update files when programs change? {#r-rse-automate-depend-programs}

Right now,
our Makefile says that each result file depends only on the corresponding data file.
But that's not true:
each result also depends on the program used to generate it,
and if we change our program,
we should regenerate our results.
To do that,
we can add the program to the prerequisites for each result:

```make
# ...phony targets...

# Regenerate results for "Moby Dick"
results/moby_dick.csv : data/moby_dick.txt bin/countwords.py
        python bin/countwords.py data/moby_dick.txt > results/moby_dick.csv

# Regenerate results for "Jane Eyre"
results/jane_eyre.csv : data/jane_eyre.txt bin/countwords.py
        python bin/countwords.py data/jane_eyre.txt > results/jane_eyre.csv
```

```shell
$ touch bin/countwords.py
$ make all
```

```text
python bin/countwords.py data/moby_dick.txt > results/moby_dick.csv
python bin/countwords.py data/jane_eyre.txt > results/jane_eyre.csv
```

The exercises will explore how we can write a rule
to tell us whether our results will be different
after a change to a program
without actually updating them.
Rules like this can help us test our programs:
if we don't think an addition or modification ought to affect the results,
but it would,
we may have some debugging to do.

## How can I reduce repetition in a Makefile? {#r-rse-automate-variables}

Our Makefile now mentions `bin/countwords.py` four times.
If we ever change the name of the program or move it to a different location,
we will have to find and replace each of those occurrences.
More importantly,
this redundancy makes our Makefile harder to understand,
just as scattering [magic numbers][magic-number] through programs
makes them harder to understand.

The solution is the same one we use in programs:
define and use [variables][variable-make].
Let's create names for the word-counting script and the command used to run it:

```make
# ...phony targets...

COUNT=bin/countwords.py
RUN_COUNT=python $(COUNT)

# Regenerate results for "Moby Dick"
results/moby_dick.csv : data/moby_dick.txt $(COUNT)
        $(RUN_COUNT) data/moby_dick.txt > results/moby_dick.csv

# Regenerate results for "Jane Eyre"
results/jane_eyre.csv : data/jane_eyre.txt $(COUNT)
        $(RUN_COUNT) data/jane_eyre.txt > results/jane_eyre.csv
```

Each definition takes the form `NAME=value`.
Variables are written in upper case by convention
so that they'll stand out from filenames
(which are usually in lower case),
but Make doesn't require this.
What *is* required is using parentheses to refer to the variable,
i.e.,
to use `$(NAME)` and not `$NAME`.
For historical reasons,
Make interprets `$NAME` to be a "variable called `N` followed by the three characers 'AME'",
If no variable called `N` exists,
`$NAME` becomes `AME`,
which is almost certainly not what we want.

As in programs,
variables don't just cut down on typing.
They also signal to readers that several things are always and exactly the same,
which reduces [cognitive load][cognitive-load].

## How can I take specific filenames out of my rules? {#r-rse-automate-autovar}

We could add a third rule to analyze a third novel and a fourth to analyze a fourth,
but that clearly wouldn't scale to analyzing hundreds or thousands of files.
Instead,
we should write a generic rule that will produce a CSV file for any book.
To do this,
we need to understand Make's [automatic variables][automatic-variable-make].
The first step is to use the very cryptic expression `$@` in the rule's action
to mean "the target of the rule".
With it,
we can replace this:

```make
# Regenerate results for "Moby Dick"
results/moby_dick.csv : data/moby_dick.txt $(COUNT)
        $(RUN_COUNT) data/moby_dick.txt > results/moby_dick.csv
```

with this:

```make
# Regenerate results for "Moby Dick"
results/moby_dick.csv : data/moby_dick.txt $(COUNT)
        $(RUN_COUNT) data/moby_dick.txt > $@
```

Make defines a value of `$@` separately for each rule,
so it always refers to that rule's target.
And yes,
`$@` is an unfortunate name:
something like `$TARGET` would have been easier to understand,
but we're stuck with it now.

The next step is to replace the explicit list of prerequisites in the action
with the automatic variable `$^`:

```make
# Regenerate results for "Jane Eyre"
results/moby_dick.csv : data/moby_dick.txt $(COUNT)
        $(RUN_COUNT) $^ > $@
```

However,
this doesn't work.
The rule's prerequisites are the novel and the word-counting program.
When Make expands the action,
the resulting command tries to process the program as if it were a data file:

```shell
python bin/countwords.py data/moby_dick.txt bin/countwords.py > results/moby_dick.csv
```

Make solves this problem with another automatic variable `$<`,
which mean "the first prerequisite".
Using it lets us rewrite our rule as:

```make
# Regenerate results for "Jane Eyre"
results/moby_dick.csv : data/moby_dick.txt $(COUNT)
        $(RUN_COUNT) $< > $@
```

`$< > $@` is hard to read, even with practice.
Using an editor with [syntax highlighting][syntax-highlighting] (Chapter \@ref(tools)) only helps a little,
so please don't ever create something this cryptic yourself.

## How can I write a generic rule to update many files? {#r-rse-automate-pattern}

We can now replace all the rules for generating results files with one [pattern rule][pattern-rule-make]
using the [wildcard][wildcard] `%`,
which matches zero or more characters in a filename.
Whatever matches `%` in the target also matches in the prerequisites,
so the rule:

```make
results/%.csv : data/%.txt $(COUNT)
        $(RUN_COUNT) $< > $@
```

will handle *Jane Eyre*, *Moby Dick*, *The Time Machine*, and every other novel in the `data` directory.
(Unfortunately,
`%` cannot be used in rules' actions,
which is why `$<` and `$@` are needed.)
With this rule in place, our entire Makefile is reduced to:

```
.PHONY: all clean

COUNT=bin/countwords.py
RUN_COUNT=python $(COUNT)

# Regenerate all results.
all : results/moby_dick.csv results/jane_eyre.csv results/time_machine.csv

# Regenerate result for any book.
results/%.csv : data/%.txt $(COUNT)
        $(RUN_COUNT) $< > $@

# Remove all generated files.
clean :
        rm -f results/*
```

To test our shortened Makefile,
let's delete all of the results files:

```shell
$ make clean
```

```text
rm -f results/*
```

and then recreate them:

```shell
$ make all
```

```text
python bin/countwords.py data/moby_dick.txt > results/moby_dick.csv
python bin/countwords.py data/jane_eyre.txt > results/jane_eyre.csv
python bin/countwords.py data/time_machine.txt > results/time_machine.csv
```

We can still rebuild individual files if we want,
since Make will take the target filename we give on the command line
and see if a pattern rule matches it:

```shell
$ touch data/jane_eyre.txt
$ make results/jane_eyre.csv
```

```text
python bin/countwords.py data/jane_eyre.txt > results/jane_eyre.csv
```

## How can I automatically define a set of files? {#r-rse-automate-functions}

Our analysis is still not fully automated:
if we add another book to `data`,
we have to remember to add its name to the `all` target in the Makefile as well.
Once again we will fix this in steps.

To start,
imagine that all the results files already exist
and we just want to update them.
We can define a variable called `RESULTS`
to be a list of all the results files
using the same wildcards we would use in the shell:

```make
RESULTS=results/*.csv
```

We can then rewrite `all` to depend on that list:

```make
# Regenerate all results.
all : $(RESULTS)
```

However,
this only works if the results files already exist:
if one doesn't,
its name won't be included in `RESULTS`
and Make won't realize that we want to generate it.

What we really want is generate the list of results files
from the list of books in the `data/` directory.
We can use a [function][function-make] to do this.
The syntax is odd because functions were added to Make long after it was first written,
but at least they have readable names.
Let's create a variable `DATA` that holds the names of all of our data files:

```make
DATA=$(wildcard data/*.txt)
```

This calls the function `wildcard` with the argument `data/*.txt`.
The result is a list of all the text files in the `data` directory,
just as we would get with `data/*.txt` in the shell.

To check that this did the right thing,
we can add another phony target called `settings`
that uses the shell command `echo` to print the names and values of our variables:

```make
.PHONY: all clean settings

# ...everything else...

# Show variables' values.
settings :
        echo COUNT: $(COUNT)
        echo DATA: $(DATA)
```

Let's run this:

```shell
$ make settings
```

```text
echo COUNT: bin/countwords.py
COUNT: bin/countwords.py
echo DATA: data/common_sense.txt data/jane_eyre.txt data/life_of_frederick_douglass.txt data/moby_dick.txt data/sense_and_sensibility.txt data/time_machine.txt
DATA: data/common_sense.txt data/jane_eyre.txt data/life_of_frederick_douglass.txt data/moby_dick.txt data/sense_and_sensibility.txt data/time_machine.txt
```

The output appears twice
because Make shows us the command it's going to run before running it.
If we put `@` before the command,
Make doesn't display it,
which makes the output easier to read:

```make
settings :
    @echo COUNT: $(COUNT)
    @echo DATA: $(DATA)
```

```shell
$ make settings
```

```text
COUNT: bin/countwords.py
DATA: data/common_sense.txt data/jane_eyre.txt data/life_of_frederick_douglass.txt data/moby_dick.txt data/sense_and_sensibility.txt data/time_machine.txt
```

We now have the names of our input files,
but what we need is the names of the corresponding output files.
Make's `patsubst` function
(short for <strong>pat</strong>tern <strong>subst</strong>itution)
does exactly this:

```
RESULTS=$(patsubst data/%.txt,results/%.csv,$(DATA))
```

The first argument to `patsubst` is the pattern to look,
which in this case is a text file in the `data` directory.
We use `%` to match the [stem][filename-stem] of the file's name,
which is the part we want to keep.

The second argument is the replacement we want.
As in a pattern rule,
Make replaces `%` in this argument with whatever matched `%` in the pattern,
which creates the name of the result file we want.
Finally,
the third argument is what to do the substitution in,
which is our list of books' names.

Let's check our worke by adding another command to the `settings` target:

```make
settings :
        @echo COUNT: $(COUNT)
        @echo DATA: $(DATA)
        @echo RESULTS: $(RESULTS)
```

```shell
$ make settings
```

```text
COUNT: bin/countwords.py
DATA: data/common_sense.txt data/jane_eyre.txt data/life_of_frederick_douglass.txt data/moby_dick.txt data/sense_and_sensibility.txt data/time_machine.txt
RESULTS: results/common_sense.csv results/jane_eyre.csv results/life_of_frederick_douglass.csv results/moby_dick.csv results/sense_and_sensibility.csv results/time_machine.csv
```

Excellent:
`DATA` has the names of the files we want to process
and `RESULTS` automatically has the names of the corresponding result files.
Let's recreate all of the latter:

```shell
$ make clean
```

```text
rm -f results/*.csv
```

```shell
$ make all
```

```text
python bin/countwords.py data/common_sense.txt > results/common_sense.csv
python bin/countwords.py data/jane_eyre.txt > results/jane_eyre.csv
python bin/countwords.py data/life_of_frederick_douglass.txt > results/life_of_frederick_douglass.csv
python bin/countwords.py data/moby_dick.txt > results/moby_dick.csv
python bin/countwords.py data/sense_and_sensibility.txt > results/sense_and_sensibility.csv
python bin/countwords.py data/time_machine.txt > results/time_machine.csv
```

Our workflow is now just two steps:
add a data file and run Make.
This is a big improvement over running things manually,
particularly as we start to add more steps like merging data files and generating plots.

## How can I document my Makefile? {#r-rse-automate-doc}

Every well-behaved program tells people how to use it [@Tasc2017].
If we run `make --help`,
for example,
we get a long list of options that Make understands.

How can we document the workflow embodied in a specific Makefile?
We could create another phony target called `help` that prints a list of available commands:

```make
.PHONY: all clean help settings

# ...other definitions...

# Show help.
help :
        @echo "all : regenerate all out-of-date results files."
        @echo "results/*.csv : regenerate a particular results file."
        @echo "clean : remove all generated files."
        @echo "settings : show the values of all variables."
        @echo "help : show this message."
```

Sooner or later,
though,
we will add a target or rule and forget to update this list.
A better approach is to format some comments in a special way
and then extract and display those comments when asked to.
We'll use `##` (a double comment marker) to indicate the lines we want displayed
and `grep` (Section \@ref(r-rse-bash-advanced-find)) to pull these lines out of the file:

```make
.PHONY: all clean help settings

COUNT=bin/countwords.py
RUN_COUNT=python $(COUNT)
DATA=$(wildcard data/*.txt)
RESULTS=$(patsubst data/%.txt,results/%.csv,$(DATA))

## all : regenerate all results.
all : $(RESULTS)

## results/%.csv : regenerate result for any book.
results/%.csv : data/%.txt $(COUNT)
        $(RUN_COUNT) $< > $@

## clean : remove all generated files.
clean :
        rm -f results/*.csv

## settings : show variables' values.
settings :
        @echo COUNT: $(COUNT)
        @echo DATA: $(DATA)
        @echo RESULTS: $(RESULTS)

## help : show this message.
help :
        @grep '^##' ./Makefile
```

Let's test:

```shell
$ make help
```

```text
## all : regenerate all results.
## results/%.csv : regenerate result for any book.
## clean : remove all generated files.
## settings : show variables' values.
## help : show this message.
```

With a bit more work we ccan remove the `##` markers,
but this is a good start.

## How can I create entire analysis pipelines? {#r-rse-automate-pipeline}

To finish our example,
we will automatically generate a collated list of word frequencies.
The target is a file called `results/collated.csv`
that depends on the results generated by `countwords.py` (Figure \@ref(fig:automate-pipelines)).

```{r automate-pipelines, echo=FALSE, fig.cap="Creating Pipelines"}
knitr::include_graphics("figures/FIXME.png")
```

To create it,
we add or change these lines in our Makefile:

```make
# ...phony targets and previous variable definitions...

COLLATE=bin/collate.py
RUN_COLLATE=python $(COLLATE)

## all : regenerate all results.
all : results/collated.csv

## results/collated.csv : collate all results.
results/collated.csv : $(RESULTS) $(COLLATE)
	$(RUN_COLLATE) $(RESULTS) > $@

```

The first two lines tell Make about the collation program,
while the change to `all` tells it what the final target of our pipeline is.
Since this target depends on the single-novel results files,
`make all` will regenerate all of those automatically.

The rule to regenerate `results/collated.csv` should look familiar by now:
it tells Make that all of the individual results have to be up-to-date
and that the final result should be regenerated if the program used to create it has changed.
One difference between the action in this rule and the actions we've seen before
is that this action uses `$(RESULTS)` directly instead of an automatic variable.
We have written the rule this way because
there isn't an automatic variable that means "all but the last prerequisite",
so there's no way to use automatic variables that wouldn't result in us trying to process our program.

## Summary {#r-rse-automate-summary}

Make's reliance on shell commands instead of direct calls to functions in Python or R
sometimes makes it clumsy to use.
However,
that also makes it very flexible:
a single Makefile can run shell commands and programs written in a variety of languages,
which makes it a great way to assemble pipelines out of whatever is lying around.

```{r automate-concept, echo=FALSE, fig.cap="Automation Concept Map"}
if (knitr::is_latex_output()) {
  knitr::include_graphics("figures/FIXME.png")
} else {
  knitr::include_graphics("figures/FIXME.png")
}
```

```{r, child="keypoints/automate.md"}
```

## Exercises {#r-rse-automate-exercises}

### Create a summary results file {#r-rse-automate-ex-create-summary-results}

-   Add a rule to Makefile to create a summary CSV file from all of the book CSV files.
-   Be careful about writing the prerequisites so that it doesn't depend on itself.

### Generate a plot for the top N words {#r-rse-automate-ex-plot-top-n}

-   Make it depend on the summary.

### Make sure the output directory exists {#r-rse-automate-ex-mkdir}

-   Why is `mkdir -p` useful?

### Report results that would change {#r-rse-automate-ex-report-change}

-   Write a rule to report which result files would actually change.
-   Hint: use `diff`.

### Create more readable help {#r-rse-automate-ex-readable-help}

-   Modify the command in the `help` action to remove the leading '##' markers from the output.

### The perils of shell wildcards {#r-rse-automate-ex-wildcard-perils}

What is wrong with writing the rule for `results/collated.csv` like this:

```make
results/collated.csv : results/*.csv
	$(RUN_COLLATE) $^ > $@
```

Hint: the fact that the result no longer depends on the program used to create it isn't the only problem.

```{r, child="./links.md"}
```
